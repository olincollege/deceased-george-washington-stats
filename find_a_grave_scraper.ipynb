{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all of the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the .HTML of a Certain Page and Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(first_name =\"George\", last_name=\"Washington\", page=\"1\"):\n",
    "    # define search url based on user input\n",
    "    url = (\n",
    "        f\"https://www.findagrave.com/memorial/search?firstname={first_name}&\"\n",
    "        f\"middlename=&lastname={last_name}&birthyear=&birthyearfilter=&\"\n",
    "        \"deathyear=&deathyearfilter=&location=&locationId=&memorialid=&mcid=&\"\n",
    "        f\"linkedToName=&datefilter=&orderby=b&plot=&page={page}#sr-1075\")\n",
    "\n",
    "    page_HTML = requests.get(url) # HTML from URL\n",
    "\n",
    "    # successful url request code is 200\n",
    "    if page_HTML.status_code != 200:\n",
    "        sys.exit(\"Connection Failed.\") # stop execution and return error\n",
    "\n",
    "    return page_HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Through All Entries for a Certain Name and Return a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(first_name =\"George\", last_name=\"Washington\"):\n",
    "    #Define the empty dataframe\n",
    "    data_table = pd.DataFrame(columns = [\"Names\", \"Dates\", \"Location of Grave\"])\n",
    "\n",
    "    # get HTML of specified page number\n",
    "    page = get_file(first_name, last_name, \"1\")\n",
    "\n",
    "    # Parse HTML into Beautiful Soup format\n",
    "    parsed = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    #Find the div containing the maximum number of pages\n",
    "    max_page = parsed.find(id = \"gotoPage\")\n",
    "\n",
    "    #max_page functions as a dictionary where we can enter the\n",
    "    #string of any element in the div to find its value\n",
    "    max_page = max_page[\"max\"]\n",
    "\n",
    "\n",
    "    #iterate through each page\n",
    "    for index in range(int(max_page)):\n",
    "\n",
    "        # get HTML of specified page number\n",
    "        page = get_file(first_name, last_name, str(int(index) + 1))\n",
    "\n",
    "        # Parse HTML into Beautiful Soup format\n",
    "        parsed = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        #Create a list of all tag with an attribute class \"memorial-item\"\n",
    "        #tags act like containers that contain attributes and text\n",
    "        grave_infos = parsed.find_all(class_ = \"memorial-item\")\n",
    "\n",
    "        #Go through each item in the list\n",
    "        for grave_info in grave_infos:\n",
    "            #First check name tag exists and contains text and includes first and last name\n",
    "            if grave_info.find(\"i\") is not None and grave_info.find(\"i\").string is not None and first_name in grave_info.find(\"i\").string and last_name in grave_info.find(\"i\").string:\n",
    "                name = grave_info.find(\"i\").string\n",
    "                #Check that birth and death date exist and does not contain unknown\n",
    "                if grave_info.find(class_ = \"birthDeathDates\") is not None and \"unknown\" not in grave_info.find(class_ = \"birthDeathDates\").string:\n",
    "                    #find the text with class = birthDeathDates\n",
    "                    date = grave_info.find(class_ = \"birthDeathDates\").string\n",
    "                else: date = \"NA\"\n",
    "\n",
    "                #make sure that the grave data actually exists\n",
    "                if grave_info.find(\"p\", attrs = {'class':'addr-cemet'}) is not None:\n",
    "                    #find the text in <p> with class = addr-cemet\n",
    "                    grave_address = grave_info.find(\"p\", attrs = {'class':'addr-cemet'}).string\n",
    "                else: grave_address = \"NA\"\n",
    "\n",
    "                #record the date in the Dates column\n",
    "                data_table = data_table.append({\"Names\": name, \"Dates\": date, \"Location of Grave\": grave_address}, ignore_index= True)\n",
    "\n",
    "    #split birthday and death date\n",
    "    data_table[[\"Birth Date\", \"Death Date\"]] = data_table[\"Dates\"].str.split(\"â€“\", expand = True, n=1)\n",
    "    #get rid of any NA values\n",
    "    data_table = data_table.dropna()\n",
    "\n",
    "    return data_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab only the years from the dates\n",
    "data[\"Death Date\"] = data[\"Death Date\"].str[-4:]\n",
    "data[\"Birth Date\"] = data[\"Birth Date\"].str[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of times named individual was born for each year\n",
    "birth_stats = data[\"Birth Date\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the count series into a dataframe\n",
    "birth_stats = birth_stats.to_frame()\n",
    "\n",
    "#for some reason count makes the objects it is counting an index so we need to make them a column\n",
    "birth_stats.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns for better clarity\n",
    "birth_stats = birth_stats.rename(columns={\"index\": \"Year\", \"Birth Date\": \"Birth Count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of anything that contains a letter\n",
    "birth_stats = birth_stats[~birth_stats.Year.str.contains(\"A|B|C|D|E|F|G|H|I|J|K|L|M|N|O|P|Q|R|S|T|U|V|W|X|Y|Z|a|b|c|d|e|f|g|h|i|j|k|l|m|n|o|p|q|r|s|t|u|v|w|x|y|z\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all of the Year and count data to integer\n",
    "birth_stats = birth_stats.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dataframe as a csv (need to change as this isn't the edited one)\n",
    "data.to_csv (r'/home/phillip/github/deceased-george-washington-stats/DataFrames/test1.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "53bd7f13955accc32fb70e0d5171fbbae9113855343752f22af5971c54171877"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
